{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo  Quantity InvoiceDate  Price  CustomerID    Country\n",
      "0    540267        96    1/6/2011   0.72       12415  Australia\n",
      "1    567085        16   9/16/2011   0.83       12434  Australia\n",
      "2    540267        36    1/6/2011   1.85       12415  Australia\n",
      "3    558537        48   6/30/2011   1.25       12424  Australia\n",
      "4    556917       144   6/15/2011   2.49       12415  Australia\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"../data/final_dataset.csv\"  # Path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (5184, 6)\n",
      "Shape after handling missing values: (5184, 6)\n",
      "Shape before removing duplicates: (5184, 6)\n",
      "Shape after removing duplicates: (4200, 6)\n",
      "Handling outliers...\n",
      "Shape after handling outliers: (4135, 6)\n",
      "Adding new metrics...\n",
      "Aggregating data...\n",
      "Daily aggregation complete.\n",
      "Weekly aggregation complete.\n",
      "Monthly aggregation complete.\n",
      "Sample transformed data:\n",
      "  InvoiceNo  Quantity InvoiceDate  Price  CustomerID    Country  TotalRevenue\n",
      "0    540267        96  2011-01-06   0.72       12415  Australia         69.12\n",
      "1    567085        16  2011-09-16   0.83       12434  Australia         13.28\n",
      "2    540267        36  2011-01-06   1.85       12415  Australia         66.60\n",
      "3    558537        48  2011-06-30   1.25       12424  Australia         60.00\n",
      "4    556917       144  2011-06-15   2.49       12415  Australia        358.56\n",
      "\n",
      "Sample daily aggregation:\n",
      "  InvoiceDate  Quantity  TotalRevenue  Transactions\n",
      "0  2010-12-01       258        363.23            14\n",
      "1  2010-12-02        22         61.70             4\n",
      "2  2010-12-03       100        264.36            11\n",
      "3  2010-12-05       498       1132.38            29\n",
      "4  2010-12-06         1          2.10             1\n",
      "\n",
      "Sample weekly aggregation:\n",
      "             InvoiceDate  Quantity  TotalRevenue  Transactions\n",
      "0  2010-11-29/2010-12-05       878       1821.67            58\n",
      "1  2010-12-06/2010-12-12      1999       3964.38            87\n",
      "2  2010-12-13/2010-12-19      1219        527.58            59\n",
      "3  2010-12-20/2010-12-26       540        753.81            19\n",
      "4  2011-01-03/2011-01-09      1252       1588.08            41\n",
      "\n",
      "Sample monthly aggregation:\n",
      "  InvoiceDate  Quantity  TotalRevenue  Transactions\n",
      "0     2010-12      4636       7067.44           223\n",
      "1     2011-01      6248      12469.86           293\n",
      "2     2011-02      6036      10180.96           239\n",
      "3     2011-03      5675      10712.70           293\n",
      "4     2011-04      4425       9007.68           240\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Handle missing values\n",
    "def handle_missing_values(df):\n",
    "    print(\"Initial shape:\", df.shape)\n",
    "    # Drop rows with missing critical fields\n",
    "    df = df.dropna(subset=['InvoiceNo', 'InvoiceDate'])\n",
    "    # Fill missing Price or Quantity with median (if applicable)\n",
    "    df['Price'] = df['Price'].fillna(df['Price'].median())\n",
    "    df['Quantity'] = df['Quantity'].fillna(df['Quantity'].median())\n",
    "    df['CustomerID'] = df['CustomerID'].fillna(-1)  # Use -1 for missing CustomerID\n",
    "    print(\"Shape after handling missing values:\", df.shape)\n",
    "    return df\n",
    "\n",
    "# Remove duplicates\n",
    "def remove_duplicates(df):\n",
    "    print(\"Shape before removing duplicates:\", df.shape)\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"Shape after removing duplicates:\", df.shape)\n",
    "    return df\n",
    "\n",
    "# Handle outliers\n",
    "def handle_outliers(df):\n",
    "    print(\"Handling outliers...\")\n",
    "    # Define thresholds\n",
    "    price_upper = df['Price'].quantile(0.99)  # 99th percentile\n",
    "    quantity_upper = df['Quantity'].quantile(0.99)\n",
    "    \n",
    "    # Filter out rows with extreme values\n",
    "    df = df[(df['Price'] <= price_upper) & (df['Quantity'] <= quantity_upper)]\n",
    "    print(\"Shape after handling outliers:\", df.shape)\n",
    "    return df\n",
    "\n",
    "# Add new metrics\n",
    "def add_new_metrics(df):\n",
    "    print(\"Adding new metrics...\")\n",
    "    df['TotalRevenue'] = df['Price'] * df['Quantity']\n",
    "    return df\n",
    "\n",
    "# Aggregate data\n",
    "def aggregate_data(df):\n",
    "    print(\"Aggregating data...\")\n",
    "    # Ensure InvoiceDate is datetime\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "    \n",
    "    # Daily aggregation\n",
    "    daily = df.groupby(df['InvoiceDate'].dt.date).agg({\n",
    "        'Quantity': 'sum',\n",
    "        'TotalRevenue': 'sum',\n",
    "        'InvoiceNo': 'count'  # Total transactions\n",
    "    }).reset_index().rename(columns={'InvoiceNo': 'Transactions'})\n",
    "    print(\"Daily aggregation complete.\")\n",
    "    \n",
    "    # Weekly aggregation\n",
    "    weekly = df.groupby(df['InvoiceDate'].dt.to_period('W')).agg({\n",
    "        'Quantity': 'sum',\n",
    "        'TotalRevenue': 'sum',\n",
    "        'InvoiceNo': 'count'\n",
    "    }).reset_index().rename(columns={'InvoiceNo': 'Transactions'})\n",
    "    print(\"Weekly aggregation complete.\")\n",
    "    \n",
    "    # Monthly aggregation\n",
    "    monthly = df.groupby(df['InvoiceDate'].dt.to_period('M')).agg({\n",
    "        'Quantity': 'sum',\n",
    "        'TotalRevenue': 'sum',\n",
    "        'InvoiceNo': 'count'\n",
    "    }).reset_index().rename(columns={'InvoiceNo': 'Transactions'})\n",
    "    print(\"Monthly aggregation complete.\")\n",
    "    \n",
    "    return daily, weekly, monthly\n",
    "\n",
    "# Main transformation function\n",
    "def transform_data(df):\n",
    "    df = handle_missing_values(df)\n",
    "    df = remove_duplicates(df)\n",
    "    df = handle_outliers(df)\n",
    "    df = add_new_metrics(df)\n",
    "    daily, weekly, monthly = aggregate_data(df)\n",
    "    return df, daily, weekly, monthly\n",
    "\n",
    "# Run the transformation\n",
    "df_transformed, daily_agg, weekly_agg, monthly_agg = transform_data(df)\n",
    "\n",
    "# Display sample results\n",
    "print(\"Sample transformed data:\")\n",
    "print(df_transformed.head())\n",
    "\n",
    "print(\"\\nSample daily aggregation:\")\n",
    "print(daily_agg.head())\n",
    "\n",
    "print(\"\\nSample weekly aggregation:\")\n",
    "print(weekly_agg.head())\n",
    "\n",
    "print(\"\\nSample monthly aggregation:\")\n",
    "print(monthly_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily aggregation saved to: ../data/daily_aggregation.csv\n",
      "Weekly aggregation saved to: ../data/weekly_aggregation.csv\n",
      "Monthly aggregation saved to: ../data/monthly_aggregation.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"final_dataset.csv\")\n",
    "# Save the aggregated data to CSV files\n",
    "import os\n",
    "\n",
    "# Function to save aggregated data\n",
    "def save_aggregated_data(daily, weekly, monthly, directory=\"../data/\"):\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    # Define file paths\n",
    "    daily_file = os.path.join(directory, \"daily_aggregation.csv\")\n",
    "    weekly_file = os.path.join(directory, \"weekly_aggregation.csv\")\n",
    "    monthly_file = os.path.join(directory, \"monthly_aggregation.csv\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    daily.to_csv(daily_file, index=False)\n",
    "    print(f\"Daily aggregation saved to: {daily_file}\")\n",
    "    \n",
    "    weekly.to_csv(weekly_file, index=False)\n",
    "    print(f\"Weekly aggregation saved to: {weekly_file}\")\n",
    "    \n",
    "    monthly.to_csv(monthly_file, index=False)\n",
    "    print(f\"Monthly aggregation saved to: {monthly_file}\")\n",
    "\n",
    "# Save the aggregated data\n",
    "save_aggregated_data(daily_agg, weekly_agg, monthly_agg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
